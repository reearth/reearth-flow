= Benchmark Suite
:toc:
:toc-placement!:

This document describes the benchmark suite for the yrs-warp WebSocket server implementation.

toc::[]

== Overview

The benchmark suite tests various aspects of the WebSocket server performance, including connection handling, document synchronization, and concurrent operations.

== Running Benchmarks

To run all benchmarks:
[source,bash]
----
cargo bench
----

Results will be saved in `target/criterion/` directory, including:

* HTML report: `target/criterion/report/index.html`
* Raw data: JSON and CSV files in benchmark-specific directories

== Benchmark Descriptions

=== Connection Tests

==== `websocket_connection`
Tests basic WebSocket connection establishment and closure.
* Measures the time to establish and properly close a WebSocket connection
* Includes a small delay between connections for stability

==== `long_connection`
Tests performance with long-lived connections.
* Simulates a connection that sends multiple updates over time
* Sends 10 updates with 50ms delays between them

=== Document Operations

==== `doc_sync`
Tests basic document synchronization.
* Creates a document with simple text content
* Measures the time to send and sync the update

==== `text_operations`
Tests multiple text operations in sequence.
* Performs 5 text insertions
* Measures the complete cycle of creating, sending, and syncing updates

==== `large_update`
Tests handling of large document updates.
* Creates a ~100KB text update
* Tests the system's performance with larger payloads

=== Concurrent Operations

==== `concurrent_clients`
Tests multiple simultaneous clients.
* Connects 5 clients simultaneously
* Each client sends a unique update
* Measures the total time for all operations to complete

==== `concurrent_clients_variable`
Tests scalability with varying numbers of clients.
* Tests with 2, 4, 8, and 16 concurrent clients
* Helps understand how performance scales with more clients

=== Broadcasting

==== `broadcast`
Tests message broadcasting performance.
* Creates 5 receiver connections
* Sends a large message that gets broadcast to all receivers
* Measures the complete broadcast cycle

==== `state_vector_sync`
Tests state vector synchronization.
* Measures the performance of state vector exchange
* Important for CRDT synchronization

== Configuration

The benchmarks are configured with:

* Default sample size: 50 samples per benchmark
* Results directory: `target/criterion/`
* Appropriate delays between operations for stability

== Interpreting Results

The HTML report provides:

* Statistical analysis of each benchmark
* Performance comparison graphs
* Detailed timing information
* Historical performance data

Key metrics to look for:

* Mean execution time
* Standard deviation
* Throughput (where applicable)
* Performance changes between runs

== Notes

* Ensure the WebSocket server is running on `localhost:8080` before running benchmarks
* Some benchmarks may take longer due to connection handling and cleanup
* Large sample sizes may increase total benchmark runtime